# üìö Statistical Machine Learning Assignments

## Assignment 1: Theoretical Foundations
**Q1** - Derive decision boundaries for multivariate Gaussians under linear transformations (Y = AX + b).  
**Q2** - Prove mean/variance of Poisson distribution and derive Bayes classification rules.  
**Q3** - Show minimum risk discriminant function for binary classification with loss matrices.  
**Q4** - Minimize Bayes risk for arbitrary PDFs with asymmetric loss functions.  

---

## Assignment 2: MNIST Classification
Implement classification on MNIST using:  
- Maximum Likelihood Estimation (MLE)  
- Principal Component Analysis (PCA)  
- Fisher's Discriminant Analysis (FDA)  
Compare performance across methods.

---

## Assignment 3: Algorithms from Scratch  
**Q1** - Find optimal function minimizing true risk in supervised learning.  
**Q2** - Compute bias/variance for linear regression models on synthetic data.  
**Q3** - Implement Decision Tree (Gini impurity, recursive splitting) without sklearn.  
**Q4** - Improve Decision Tree via bagging and measure OOB error.  
**Q5** - Polynomial regression evaluation with 5-fold CV on y=sin(x)+noise.  

---

## Assignment 4: Advanced ML Techniques  
**Q1** - AdaBoost from scratch using decision stumps (MNIST 0/1 classes).  
**Q2** - Gradient Boosting for regression (squared/absolute loss) on synthetic data.  
**Q3** - Binary classification NN with 2D inputs and 1-hidden-layer (sigmoid).  

---

## üõ† Usage  
1. Navigate to assignment folder (e.g., `Assignment_1/`)  
2. Run Jupyter notebooks or Python scripts  
3. View reports/plots in `Results/` subfolders  

---

## üìù Notes  
- Theory assignments include derivations.  
- Coding assignments require NumPy/Pandas (no sklearn for Q3 in Assignment 3).  
- Datasets: Synthetic (generated) + MNIST subset.  

Maintained by Sahil Tushir | SML 2025  
