# âš¡ Assignment 4: Advanced ML Algorithms  
**Statistical Machine Learning | Due: [DD/MM/YYYY] @ 11:59PM**  
*Implement AdaBoost, Gradient Boosting, and Neural Networks from scratch*

---

## ðŸŽ¯ Objectives
1. **AdaBoost**: Binary classification on MNIST using decision stumps  
2. **Gradient Boosting**: Regression with squared/absolute loss  
3. **Neural Network**: Binary classifier with sigmoid activation  

---

## ðŸ“‚ Repository Structure
```bash
A4/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ adaboost/                # Q1
â”‚   â”‚   â”œâ”€â”€ stump.py            # Decision stump implementation
â”‚   â”‚   â”œâ”€â”€ boosting.py         # Weight update logic
â”‚   â”‚   â””â”€â”€ mnist_pca.py        # PCA preprocessing (â†’5D)
â”‚   â”œâ”€â”€ gradient_boosting/       # Q2
â”‚   â”‚   â”œâ”€â”€ losses.py           # Squared/Absolute loss
â”‚   â”‚   â””â”€â”€ regression.py       # Sequential stump fitting
â”‚   â””â”€â”€ neural_net/             # Q3
â”‚       â”œâ”€â”€ nn.py               # Forward/backward pass
â”‚       â””â”€â”€ synthetic_data.py   # Gaussian dataset gen
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mnist_subset/           # Classes 0 and 1 only
â”‚   â””â”€â”€ synthetic_regression/   # sin(2Ï€x)+cos(2Ï€x)+noise
â””â”€â”€ results/
    â”œâ”€â”€ Q1_adaboost/            # Accuracy vs rounds plot
    â”œâ”€â”€ Q2_gb/                  # Train/test loss curves
    â””â”€â”€ Q3_nn/                  # Decision boundary plot
